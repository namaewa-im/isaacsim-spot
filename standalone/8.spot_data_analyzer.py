#!/usr/bin/env python3
"""
Spot LeRobot ë°ì´í„° ë¶„ì„ê¸°
Parquet íŒŒì¼ì„ ì½ì–´ì„œ ì—´ ì •ë³´ì™€ ë°ì´í„° ìƒ˜í”Œì„ ì¶œë ¥í•©ë‹ˆë‹¤.
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path

class SpotDataAnalyzer:
    def __init__(self, data_dir="spot_lerobot_data/20250811"):
        self.data_dir = Path(data_dir)
        
    def analyze_parquet_file(self, filename, num_rows=10):
        """Parquet íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        filepath = self.data_dir / filename
        
        if not filepath.exists():
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
            return
            
        print(f"=== {filename} ë¶„ì„ ===")
        print(f"íŒŒì¼ ê²½ë¡œ: {filepath}")
        print(f"íŒŒì¼ í¬ê¸°: {filepath.stat().st_size / 1024:.1f} KB")
        print()
        
        # Parquet íŒŒì¼ ì½ê¸°
        try:
            df = pd.read_parquet(filepath)
        except Exception as e:
            print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return
            
        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
        print("ğŸ“Š ê¸°ë³¸ ì •ë³´:")
        print(f"  - í–‰ ìˆ˜: {len(df):,}")
        print(f"  - ì—´ ìˆ˜: {len(df.columns)}")
        print(f"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024:.1f} KB")
        print()
        
        # ì—´ ì •ë³´ ì¶œë ¥
        print("ğŸ“‹ ì—´ ì •ë³´:")
        for i, col in enumerate(df.columns):
            dtype = df[col].dtype
            non_null = df[col].count()
            null_count = len(df) - non_null
            
            print(f"  {i+1:2d}. {col:20s} | {str(dtype):12s} | {non_null:6d} non-null | {null_count:3d} null")
            
            # ì²« ë²ˆì§¸ ê°’ ìƒ˜í”Œ ì¶œë ¥
            if non_null > 0:
                first_val = df[col].iloc[0]
                if isinstance(first_val, (list, np.ndarray)):
                    print(f"       ìƒ˜í”Œ: {type(first_val).__name__} ê¸¸ì´ {len(first_val)}")
                else:
                    print(f"       ìƒ˜í”Œ: {first_val}")
        print()
        
        # ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
        print(f"ğŸ“„ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ {num_rows}í–‰):")
        print(df.head(num_rows).to_string())
        print()
        
        # í†µê³„ ì •ë³´ (ìˆ˜ì¹˜í˜• ì—´ë§Œ)
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print("ğŸ“ˆ ìˆ˜ì¹˜í˜• ì—´ í†µê³„:")
            print(df[numeric_cols].describe())
            print()
            
        # íŠ¹ë³„í•œ ì—´ë“¤ ë¶„ì„
        self._analyze_special_columns(df)
        
    def _analyze_special_columns(self, df):
        """íŠ¹ë³„í•œ ì—´ë“¤ì„ ìì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤."""
        print("ğŸ” íŠ¹ë³„í•œ ì—´ ë¶„ì„:")
        
        # observation ì—´ ë¶„ì„
        if 'observation' in df.columns:
            obs_data = df['observation'].iloc[0]
            if isinstance(obs_data, list):
                print(f"  - observation: {len(obs_data)}ì°¨ì› ë²¡í„°")
                print(f"    ìƒ˜í”Œ: {obs_data[:5]}... (ì²˜ìŒ 5ê°œ ê°’)")
                
        # action ì—´ ë¶„ì„
        if 'action' in df.columns:
            action_data = df['action'].iloc[0]
            if isinstance(action_data, list):
                print(f"  - action: {len(action_data)}ì°¨ì› ë²¡í„°")
                print(f"    ìƒ˜í”Œ: {action_data[:5]}... (ì²˜ìŒ 5ê°œ ê°’)")
                
        # command ì—´ ë¶„ì„
        if 'command' in df.columns:
            cmd_data = df['command'].iloc[0]
            if isinstance(cmd_data, list):
                print(f"  - command: {len(cmd_data)}ì°¨ì› ë²¡í„° (vx, vy, wz)")
                print(f"    ìƒ˜í”Œ: {cmd_data}")
                
        # timestamp ë¶„ì„
        if 'timestamp' in df.columns:
            timestamps = df['timestamp']
            print(f"  - timestamp: {timestamps.min():.3f}s ~ {timestamps.max():.3f}s")
            print(f"    ê°„ê²©: {timestamps.diff().mean():.3f}s (í‰ê· )")
            
        # episode_index ë¶„ì„
        if 'episode_index' in df.columns:
            ep_indices = df['episode_index']
            print(f"  - episode_index: {ep_indices.min()} ~ {ep_indices.max()}")
            
        # task_index ë¶„ì„
        if 'task_index' in df.columns:
            task_indices = df['task_index']
            print(f"  - task_index: {task_indices.min()} ~ {task_indices.max()}")
            
        print()
        
    def list_all_files(self):
        """ëª¨ë“  Parquet íŒŒì¼ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
        parquet_files = list(self.data_dir.glob("*.parquet"))
        parquet_files.sort()
        
        print(f"ğŸ“ {self.data_dir} í´ë”ì˜ Parquet íŒŒì¼ ëª©ë¡:")
        print(f"ì´ {len(parquet_files)}ê°œ íŒŒì¼")
        print()
        
        for i, filepath in enumerate(parquet_files):
            size_kb = filepath.stat().st_size / 1024
            print(f"{i+1:2d}. {filepath.name:20s} | {size_kb:6.1f} KB")
            
        return parquet_files

def main():
    analyzer = SpotDataAnalyzer()
    
    # ëª¨ë“  íŒŒì¼ ëª©ë¡ ì¶œë ¥
    files = analyzer.list_all_files()
    print("\n" + "="*60 + "\n")
    
    # ì²« ë²ˆì§¸ íŒŒì¼ ë¶„ì„ (ì˜ˆì‹œ)
    if files:
        first_file = files[0].name
        print(f"ì²« ë²ˆì§¸ íŒŒì¼ '{first_file}' ë¶„ì„ ì¤‘...")
        analyzer.analyze_parquet_file(first_file, num_rows=5)
        
        # ë‹¤ë¥¸ íŒŒì¼ë„ ë¶„ì„í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
        # analyzer.analyze_parquet_file("task01_ep00.parquet", num_rows=3)
        # analyzer.analyze_parquet_file("task07_ep04.parquet", num_rows=3)

if __name__ == "__main__":
    main() 